"""
DANN Training Script - Final Version
"""

import argparse
import os
import torch
import torch.nn as nn
from torch.nn.parallel import DataParallel
import wandb
from ignite.engine import Events, Engine
from ignite.contrib.handlers import ProgressBar

from domain_discriminator import DomainDiscriminator, DANNClassifier, calculate_lambda_p
import utils


def create_train_step(classifier, domain_discriminator, optimizer, scheduler, 
                     iter_target, device, config):
    """å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—é–¢æ•°ï¼ˆç–¾æ‚£åˆ†é¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½åŠ ç‰ˆï¼‰"""
    cls_criterion = nn.CrossEntropyLoss()
    domain_criterion = nn.BCELoss()
    trade_off = config.get('dann', {}).get('trade_off', 1.0)
    max_epochs = config['train']['epoch']
    
    # å‰å‡¦ç†é–¢æ•°ã‚’äº‹å‰ã«å–å¾—
    _, pre, _, _, _ = utils.get_model_and_processors(config, device)
    
    def train_step(engine, batch):
        classifier.train()
        domain_discriminator.train()
        optimizer.zero_grad()
        
        try:
            # ã‚½ãƒ¼ã‚¹ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒãƒƒãƒã‚’å–å¾—
            x_s, y_s = utils.safe_batch_processing(batch, device, pre, is_evaluation=False)
            target_batch = next(iter_target)
            x_t, _ = utils.safe_batch_processing(target_batch, device, pre, is_evaluation=False)
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å–å¾—
            config_batch_size = config.get('dataset', {}).get('batch_size', 128)
            half_size = config_batch_size // 2  # 64
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            if engine.state.epoch <= 2 and engine.state.iteration <= 3:
                print(f"ğŸ” Batch size debug:")
                print(f"  Config batch_size: {config_batch_size}")
                print(f"  Target half_size: {half_size}")
                if isinstance(x_s, torch.Tensor):
                    print(f"  Source actual size: {x_s.shape[0]}")
                elif isinstance(x_s, dict):
                    sample_tensor = next(iter(x_s.values()))
                    print(f"  Source actual size: {sample_tensor.shape[0]}")
                if isinstance(x_t, torch.Tensor):
                    print(f"  Target actual size: {x_t.shape[0]}")
                elif isinstance(x_t, dict):
                    sample_tensor = next(iter(x_t.values()))
                    print(f"  Target actual size: {sample_tensor.shape[0]}")
            
            # ãƒ‡ãƒ¼ã‚¿ã®å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
            if isinstance(x_s, torch.Tensor):
                actual_source_size = x_s.shape[0]
            elif isinstance(x_s, dict):
                actual_source_size = next(iter(x_s.values())).shape[0]
            else:
                actual_source_size = len(x_s)
            
            if isinstance(x_t, torch.Tensor):
                actual_target_size = x_t.shape[0]
            elif isinstance(x_t, dict):
                actual_target_size = next(iter(x_t.values())).shape[0]
            else:
                actual_target_size = len(x_t)
            
            # â˜… ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®è­¦å‘Š
            if actual_source_size < half_size:
                print(f"âš ï¸ Warning: Source batch too small ({actual_source_size} < {half_size})")
                half_size = min(half_size, actual_source_size)
            
            if actual_target_size < half_size:
                print(f"âš ï¸ Warning: Target batch too small ({actual_target_size} < {half_size})")
                half_size = min(half_size, actual_target_size)
            
            if half_size < 8:  # æœ€å°ãƒãƒƒãƒã‚µã‚¤ã‚ºç¢ºä¿
                print(f"âŒ CRITICAL: Batch size too small: {half_size}")
                print(f"Source: {actual_source_size}, Target: {actual_target_size}")
                raise ValueError(f"Insufficient data for mixed batch: source={actual_source_size}, target={actual_target_size}")
            
            # æ··åˆãƒãƒƒãƒã‚’ä½œæˆï¼ˆã‚½ãƒ¼ã‚¹64 + ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ64 = 128ï¼‰
            if isinstance(x_s, torch.Tensor) and isinstance(x_t, torch.Tensor):
                # ãƒ†ãƒ³ã‚½ãƒ«ã®å ´åˆ
                mixed_x = torch.cat([x_s[:half_size], x_t[:half_size]], dim=0)
                mixed_y_source = y_s[:half_size]
                
            elif isinstance(x_s, dict) and isinstance(x_t, dict):
                # è¾æ›¸ã®å ´åˆ
                mixed_x = {}
                for key in x_s.keys():
                    if key in x_t and hasattr(x_s[key], 'shape') and hasattr(x_t[key], 'shape'):
                        mixed_x[key] = torch.cat([x_s[key][:half_size], x_t[key][:half_size]], dim=0)
                    else:
                        # ã‚­ãƒ¼ãŒä¸€è‡´ã—ãªã„å ´åˆã¯ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ï¼ˆè­¦å‘Šå‡ºåŠ›ï¼‰
                        print(f"âš ï¸ Key '{key}' not found in target, using source data only")
                        mixed_x[key] = x_s[key][:half_size]
                
                mixed_y_source = y_s[:half_size]
            else:
                raise ValueError(f"Incompatible data types: {type(x_s)} and {type(x_t)}")
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆï¼ˆ0: ã‚½ãƒ¼ã‚¹[0:half_size], 1: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ[half_size:2*half_size]ï¼‰
            domain_labels = torch.cat([
                torch.zeros(half_size, 1),  # ã‚½ãƒ¼ã‚¹éƒ¨åˆ†
                torch.ones(half_size, 1)    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéƒ¨åˆ†
            ], dim=0).to(device)
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæˆåŠŸæ™‚ï¼‰
            if engine.state.epoch <= 2 and engine.state.iteration <= 3:
                print(f"âœ“ Mixed batch created successfully:")
                print(f"  Source samples: {half_size} (indices 0:{half_size})")
                print(f"  Target samples: {half_size} (indices {half_size}:{half_size*2})")
                print(f"  Total batch size: {half_size*2}")
                if isinstance(mixed_x, dict):
                    for k, v in mixed_x.items():
                        if hasattr(v, 'shape'):
                            print(f"  {k} shape: {v.shape}")
                else:
                    print(f"  Mixed batch shape: {mixed_x.shape}")
                print(f"  Domain labels shape: {domain_labels.shape}")
            
            # GRLå¼·åº¦èª¿æ•´
            alpha = 1.0  # å›ºå®šå€¤
            utils.set_alpha_safely(domain_discriminator, alpha)
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã§alphaå€¤ã‚’ç¢ºèª
            if engine.state.epoch <= 2 and engine.state.iteration <= 3:
                print(f"  GRL alpha: {alpha:.4f} (fixed)")
            
            # åˆ†é¡å™¨ã§ç‰¹å¾´æŠ½å‡ºã¨åˆ†é¡
            mixed_pred, mixed_features = classifier(mixed_x)
            
            # åˆ†é¡æå¤±ï¼ˆã‚½ãƒ¼ã‚¹éƒ¨åˆ†ã®ã¿ï¼šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹0ã‹ã‚‰half_size-1ï¼‰
            source_pred = mixed_pred[:half_size]
            cls_loss = cls_criterion(source_pred, mixed_y_source)
            
            # â˜… ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥ï¼ˆGRLã‚’é€šã—ã¦å‹¾é…åè»¢ï¼‰
            # domain_discriminatorã®å†…éƒ¨ã§mixed_featuresãŒGRLã‚’é€šéã—ã¦å‹¾é…åè»¢
            domain_pred = domain_discriminator(mixed_features)
            domain_loss = domain_criterion(domain_pred, domain_labels)
            
            # ç·æå¤±ï¼ˆé‡è¦ï¼šdomain_lossã¯GRLã«ã‚ˆã‚Šåˆ†é¡å™¨ã¸ã®å‹¾é…ã‚’åè»¢ï¼‰
            total_loss = cls_loss + trade_off * domain_loss
            
            # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
            # ã“ã“ã§GRLã®å‹¾é…åè»¢ãŒåŠ¹æœã‚’ç™ºæ®ï¼š
            # - cls_lossã®å‹¾é…ï¼šåˆ†é¡å™¨ã‚’ã€Œè‰¯ã„åˆ†é¡ã€æ–¹å‘ã«æ›´æ–°
            # - domain_lossã®å‹¾é…ï¼šGRLã«ã‚ˆã‚Šåˆ†é¡å™¨ã‚’ã€Œãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥å›°é›£ã€æ–¹å‘ã«æ›´æ–°
            total_loss.backward()
            optimizer.step()
            if scheduler is not None:
                scheduler.step()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            with torch.no_grad():
                # â˜… ç–¾æ‚£åˆ†é¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå­¦ç¿’æ™‚ï¼‰
                source_pred_np = source_pred.detach().cpu().numpy()
                mixed_y_source_np = mixed_y_source.detach().cpu().numpy()
                
                # åˆ†é¡ç²¾åº¦
                source_acc = (source_pred.argmax(dim=1) == mixed_y_source).float().mean()
                
                # åˆ†é¡AUC
                try:
                    from sklearn.metrics import roc_auc_score
                    n_classes = source_pred.shape[1]
                    if n_classes == 2:
                        source_pred_prob = torch.softmax(source_pred, dim=1)[:, 1].detach().cpu().numpy()
                        cls_auc = roc_auc_score(mixed_y_source_np, source_pred_prob)
                    else:
                        source_pred_prob = torch.softmax(source_pred, dim=1).detach().cpu().numpy()
                        cls_auc = roc_auc_score(mixed_y_source_np, source_pred_prob, multi_class='ovr')
                except Exception as e:
                    print(f"âš ï¸ Classification AUC calculation failed: {e}")
                    cls_auc = 0.5
                
                # åˆ†é¡Macro-Sensitivity
                cls_macro_sens = utils.macro_sensitivity(source_pred_np, mixed_y_source_np, source_pred.shape[1])
                
                # â˜… ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå­¦ç¿’æ™‚ï¼‰
                domain_pred_binary = (domain_pred > 0.5).float()
                domain_acc = (domain_pred_binary == domain_labels).float().mean()
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥AUC
                try:
                    domain_pred_np = domain_pred.detach().cpu().numpy().flatten()
                    domain_labels_np = domain_labels.detach().cpu().numpy().flatten()
                    domain_auc = roc_auc_score(domain_labels_np, domain_pred_np)
                except Exception as e:
                    print(f"âš ï¸ Domain AUC calculation failed: {e}")
                    domain_auc = 0.5
            
            return {
                # å…¨ä½“æå¤±
                "loss": total_loss.item(),
                
                # ç–¾æ‚£åˆ†é¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå­¦ç¿’æ™‚ï¼‰
                "cls_loss": cls_loss.item(),
                "cls_acc": source_acc.item(),
                "cls_auc": cls_auc,
                "cls_macro_sensitivity": cls_macro_sens,
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå­¦ç¿’æ™‚ï¼‰
                "domain_loss": domain_loss.item(),
                "domain_acc": domain_acc.item(),
                "domain_auc": domain_auc,
                
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                "alpha": alpha,
                "batch_size": half_size * 2,
                "source_samples": half_size,
                "target_samples": half_size
            }
            
        except Exception as e:
            print(f"âŒ Training step failed: {e}")
            import traceback
            traceback.print_exc()
            raise e
    
    return train_step


def create_evaluation_step(classifier, domain_discriminator, device, config):
    """è©•ä¾¡ã‚¹ãƒ†ãƒƒãƒ—é–¢æ•°ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³AUCä¿®æ­£ç‰ˆï¼‰"""
    # å‰å‡¦ç†é–¢æ•°ã‚’äº‹å‰ã«å–å¾—
    _, pre, _, _, _ = utils.get_model_and_processors(config, device)
    
    # æå¤±é–¢æ•°ã‚’å®šç¾©
    cls_criterion = nn.CrossEntropyLoss()
    domain_criterion = nn.BCELoss()
    
    def evaluation_step(engine, batch):
        classifier.eval()
        domain_discriminator.eval()
        with torch.no_grad():
            try:
                x, y = utils.safe_batch_processing(batch, device, pre, is_evaluation=True)
                
                # â˜… ç–¾æ‚£åˆ†é¡ã®è©•ä¾¡ï¼ˆã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
                y_pred, features = classifier(x)
                
                cls_loss = cls_criterion(y_pred, y)
                correct = (y_pred.argmax(dim=1) == y).float().mean()
                
                # CPUã«ç§»å‹•ã—ã¦numpyé…åˆ—ã«å¤‰æ›
                y_pred_np = y_pred.detach().cpu().numpy()
                y_true_np = y.detach().cpu().numpy()
                
                # macro-sensitivityè¨ˆç®—
                n_classes = y_pred.shape[1]
                macro_sens = utils.macro_sensitivity(y_pred_np, y_true_np, n_classes)
                
                # AUCè¨ˆç®—
                try:
                    from sklearn.metrics import roc_auc_score
                    if n_classes == 2:
                        y_pred_prob = torch.softmax(y_pred, dim=1)[:, 1].detach().cpu().numpy()
                        auc = roc_auc_score(y_true_np, y_pred_prob)
                    else:
                        y_pred_prob = torch.softmax(y_pred, dim=1).detach().cpu().numpy()
                        auc = roc_auc_score(y_true_np, y_pred_prob, multi_class='ovr')
                except Exception as e:
                    auc = 0.5
                
                return {
                    "cls_loss": cls_loss.item(),
                    "cls_accuracy": correct.item(),
                    "cls_auc": auc,
                    "cls_macro_sensitivity": macro_sens,
                    "source_features": features,  # â˜… ã‚½ãƒ¼ã‚¹ç‰¹å¾´ã‚’è¿”ã™
                    "source_batch_size": x.shape[0] if isinstance(x, torch.Tensor) else next(iter(x.values())).shape[0]
                }
                    
            except Exception as e:
                print(f"âŒ Evaluation step failed: {e}")
                return {
                    "cls_loss": 1.0, "cls_accuracy": 0.0, "cls_auc": 0.5, "cls_macro_sensitivity": 0.0,
                    "source_features": torch.zeros(1, 256).to(device), "source_batch_size": 1
                }
    
    return evaluation_step


def create_domain_evaluation_step(domain_discriminator, iter_target, device, config):
    """ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥å°‚ç”¨è©•ä¾¡ã‚¹ãƒ†ãƒƒãƒ—"""
    # å‰å‡¦ç†é–¢æ•°ã‚’äº‹å‰ã«å–å¾—
    _, pre, _, _, _ = utils.get_model_and_processors(config, device)
    domain_criterion = nn.BCELoss()
    
    def domain_evaluation_step(source_features, source_batch_size):
        """ã‚½ãƒ¼ã‚¹ç‰¹å¾´ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹å¾´ã§ãƒ‰ãƒ¡ã‚¤ãƒ³AUCè©•ä¾¡"""
        domain_discriminator.eval()
        with torch.no_grad():
            try:
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒã‚’å–å¾—
                target_batch = next(iter_target)
                x_t, _ = utils.safe_batch_processing(target_batch, device, pre, is_evaluation=True)
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹å¾´ã‚’æŠ½å‡ºï¼ˆåˆ†é¡å™¨ã¯evalãƒ¢ãƒ¼ãƒ‰ã®ã¾ã¾ï¼‰
                if hasattr(domain_discriminator, 'module'):
                    # DataParallel ã®å ´åˆã€åˆ†é¡å™¨ã‚’å–å¾—
                    classifier = domain_discriminator.module.classifier if hasattr(domain_discriminator.module, 'classifier') else None
                else:
                    classifier = domain_discriminator.classifier if hasattr(domain_discriminator, 'classifier') else None
                
                if classifier is None:
                    # åˆ†é¡å™¨ã¸ã®å‚ç…§ãŒãªã„å ´åˆã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‹ã‚‰å–å¾—ï¼ˆãƒˆãƒªãƒƒã‚­ãƒ¼ï¼‰
                    print("âš ï¸ Warning: Cannot access classifier from domain_discriminator")
                    return 0.5, 0.5, 1.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                
                _, target_features = classifier(x_t)
                
                # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’çµ±ä¸€
                min_size = min(source_batch_size, target_features.shape[0])
                source_features_eval = source_features[:min_size]
                target_features_eval = target_features[:min_size]
                
                # æ··åˆç‰¹å¾´ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ©ãƒ™ãƒ«
                mixed_features = torch.cat([source_features_eval, target_features_eval], dim=0)
                domain_labels = torch.cat([
                    torch.zeros(min_size, 1),  # ã‚½ãƒ¼ã‚¹
                    torch.ones(min_size, 1)    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
                ], dim=0).to(device)
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥
                domain_pred = domain_discriminator(mixed_features)
                domain_acc = ((domain_pred > 0.5).float() == domain_labels).float().mean()
                domain_loss = domain_criterion(domain_pred, domain_labels)
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥AUC
                try:
                    domain_pred_np = domain_pred.detach().cpu().numpy().flatten()
                    domain_labels_np = domain_labels.detach().cpu().numpy().flatten()
                    domain_auc = roc_auc_score(domain_labels_np, domain_pred_np)
                except Exception as e:
                    print(f"âš ï¸ Domain AUC calculation failed: {e}")
                    domain_auc = 0.5
                
                return domain_auc, domain_acc.item(), domain_loss.item()
                
            except Exception as e:
                print(f"âŒ Domain evaluation failed: {e}")
                return 0.5, 0.5, 1.0
    
    return domain_evaluation_step


def main(fold, device_ids, primary_device, out_dir, parallel_mode, **config):
    """ãƒ¡ã‚¤ãƒ³å­¦ç¿’é–¢æ•°"""
    
    print(f"ğŸš€ Starting DANN Training")
    print(f"Device IDs: {device_ids}, Primary: {primary_device}")
    
    # åˆæœŸåŒ–
    wandb.init(
        project="ResNet18_DANN_final",
        name=f"dann_fold{fold}" if fold is not None else "dann_holdout",
        config=config,
        dir=out_dir,
        tags=["dann", "final"]
    )
    
    # CUDAç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    torch.cuda.set_device(primary_device)
    g = utils.setup_cuda_environment(device_ids, config['train']['seed'])
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
    print(f"ğŸ“‚ Loading datasets...")
    loader_src, loader_eval_tr, loader_eval_vl, loader_target = utils.get_datasets(config, fold, g)
    iter_target = utils.ForeverDataIterator(loader_target)
    
    # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    print(f"ğŸ—ï¸ Building models...")
    backbone, pre, post, func, met = utils.get_model_and_processors(config, primary_device)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒã§ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã®ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰
    print(f"ğŸ” Checking backbone compatibility...")
    sample_batch = next(iter(loader_src))
    x_sample, y_sample = utils.safe_batch_processing(sample_batch, primary_device, pre, is_evaluation=False)
    
    print(f"Sample input type: {type(x_sample)}")
    if isinstance(x_sample, dict):
        print(f"Sample input keys: {list(x_sample.keys())}")
        for k, v in x_sample.items():
            if hasattr(v, 'shape'):
                print(f"  {k} shape: {v.shape}")
    else:
        print(f"Sample input shape: {x_sample.shape}")
    
    # DANNè¨­å®š
    num_classes = config['model']['n_class']
    bottleneck_dim = config.get('dann', {}).get('bottleneck_dim', 256)
    domain_hidden = config.get('dann', {}).get('domain_hidden_size', 1024)
    
    print(f"ğŸ“Š DANN Configuration:")
    print(f"  Num classes: {num_classes}")
    print(f"  Bottleneck dim: {bottleneck_dim}")
    print(f"  Domain hidden: {domain_hidden}")
    
    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    classifier = DANNClassifier(backbone, num_classes, bottleneck_dim).to(primary_device)
    domain_discriminator = DomainDiscriminator(
        initial_feature_dim=bottleneck_dim,
        hidden_dim=domain_hidden
    ).to(primary_device)
    
    # GPUä¸¦åˆ—åŒ–
    if len(device_ids) > 1 and parallel_mode == 'DataParallel':
        classifier = DataParallel(classifier, device_ids=device_ids)
        domain_discriminator = DataParallel(domain_discriminator, device_ids=device_ids)
        print(f"âœ“ Using DataParallel on GPUs: {device_ids}")
    
    # æœ€é©åŒ–è¨­å®š
    all_params = list(classifier.parameters()) + list(domain_discriminator.parameters())
    optimizer = utils.init_optimizer(all_params, config)
    scheduler = utils.get_scheduler(optimizer, config)
    
    # ã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆ
    train_step = create_train_step(classifier, domain_discriminator, optimizer, scheduler,
                                  iter_target, primary_device, config)
    trainer = Engine(train_step)
    
    # è©•ä¾¡ã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆï¼ˆä¿®æ­£ç‰ˆï¼‰
    evaluation_step = create_evaluation_step(classifier, domain_discriminator, primary_device, config)
    domain_evaluation_step = create_domain_evaluation_step(domain_discriminator, iter_target, primary_device, config)
    eval_tr = Engine(evaluation_step)
    eval_vl = Engine(evaluation_step)
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    pbar = ProgressBar()
    pbar.attach(trainer, output_transform=lambda x: {'loss': x['loss']})
    
    # ãƒ­ã‚°å‡¦ç†ï¼ˆä¿®æ­£ç‰ˆï¼šæ­£ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³AUCè¨ˆç®—ï¼‰
    @trainer.on(Events.EPOCH_COMPLETED)
    def log_results(engine):
        out = engine.state.output
        
        # å­¦ç¿’æ™‚ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆæ¯ã‚¨ãƒãƒƒã‚¯ï¼‰
        train_metrics = {
            "epoch": engine.state.epoch,
            
            # â˜… å­¦ç¿’æ™‚ - ç–¾æ‚£åˆ†é¡
            "train/cls_loss": out['cls_loss'],
            "train/cls_accuracy": out['cls_acc'],
            "train/cls_auc": out['cls_auc'],
            "train/cls_macro_sensitivity": out['cls_macro_sensitivity'],
            
            # â˜… å­¦ç¿’æ™‚ - ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥
            "train/domain_loss": out['domain_loss'],
            "train/domain_accuracy": out['domain_acc'],
            "train/domain_auc": out['domain_auc'],
            
            # â˜… å­¦ç¿’æ™‚ - ãƒ¢ãƒ‡ãƒ«å…¨ä½“æå¤±
            "train/loss": out['loss']
        }
        
        print(f"Epoch {engine.state.epoch:3d} - "
              f"Loss: {out['loss']:.4f} "
              f"(Cls: {out['cls_loss']:.4f}, Domain: {out['domain_loss']:.4f}) | "
              f"Cls Acc: {out['cls_acc']:.3f}, Cls AUC: {out['cls_auc']:.3f}, "
              f"Domain Acc: {out['domain_acc']:.3f}, Domain AUC: {out['domain_auc']:.3f}")
        
        # è©•ä¾¡å®Ÿè¡Œï¼ˆæ¯ã‚¨ãƒãƒƒã‚¯ï¼‰
        classifier.eval()
        domain_discriminator.eval()
        try:
            # Trainè©•ä¾¡
            eval_tr.run(loader_eval_tr, max_epochs=1)
            train_eval_output = eval_tr.state.output
            
            # Validationè©•ä¾¡
            eval_vl.run(loader_eval_vl, max_epochs=1)
            val_output = eval_vl.state.output
            
            # â˜… ãƒ‰ãƒ¡ã‚¤ãƒ³AUCè©•ä¾¡ï¼ˆã‚½ãƒ¼ã‚¹+ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ··åˆï¼‰
            train_domain_auc, train_domain_acc, train_domain_loss = domain_evaluation_step(
                train_eval_output["source_features"], train_eval_output["source_batch_size"]
            )
            
            val_domain_auc, val_domain_acc, val_domain_loss = domain_evaluation_step(
                val_output["source_features"], val_output["source_batch_size"]
            )
            
            # è©•ä¾¡æ™‚ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿½åŠ 
            train_metrics.update({
                # â˜… Trainè©•ä¾¡ - ç–¾æ‚£åˆ†é¡
                "train_eval/cls_loss": train_eval_output["cls_loss"],
                "train_eval/cls_accuracy": train_eval_output["cls_accuracy"],
                "train_eval/cls_auc": train_eval_output["cls_auc"],
                "train_eval/cls_macro_sensitivity": train_eval_output["cls_macro_sensitivity"],
                
                # â˜… Trainè©•ä¾¡ - ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥ï¼ˆä¿®æ­£ç‰ˆï¼‰
                "train_eval/domain_loss": train_domain_loss,
                "train_eval/domain_accuracy": train_domain_acc,
                "train_eval/domain_auc": train_domain_auc,
                
                # â˜… Trainè©•ä¾¡ - ãƒ¢ãƒ‡ãƒ«å…¨ä½“æå¤±
                "train_eval/loss": train_eval_output["cls_loss"] + train_domain_loss,
                
                # â˜… Validationè©•ä¾¡ - ç–¾æ‚£åˆ†é¡
                "val/cls_loss": val_output["cls_loss"],
                "val/cls_accuracy": val_output["cls_accuracy"],
                "val/cls_auc": val_output["cls_auc"],
                "val/cls_macro_sensitivity": val_output["cls_macro_sensitivity"],
                
                # â˜… Validationè©•ä¾¡ - ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥ï¼ˆä¿®æ­£ç‰ˆï¼‰
                "val/domain_loss": val_domain_loss,
                "val/domain_accuracy": val_domain_acc,
                "val/domain_auc": val_domain_auc,
                
                # â˜… Validationè©•ä¾¡ - ãƒ¢ãƒ‡ãƒ«å…¨ä½“æå¤±
                "val/loss": val_output["cls_loss"] + val_domain_loss
            })
            
        except Exception as e:
            print(f"âš ï¸ Evaluation failed: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            train_metrics.update({
                "train_eval/cls_loss": 1.0, "train_eval/cls_accuracy": 0.0, "train_eval/cls_auc": 0.5, "train_eval/cls_macro_sensitivity": 0.0,
                "train_eval/domain_loss": 1.0, "train_eval/domain_accuracy": 0.5, "train_eval/domain_auc": 0.5, "train_eval/loss": 2.0,
                "val/cls_loss": 1.0, "val/cls_accuracy": 0.0, "val/cls_auc": 0.5, "val/cls_macro_sensitivity": 0.0,
                "val/domain_loss": 1.0, "val/domain_accuracy": 0.5, "val/domain_auc": 0.5, "val/loss": 2.0
            })
        
        # wandbã«è¨˜éŒ²
        wandb.log(train_metrics)
        
        classifier.train()
        domain_discriminator.train()
    
    # å­¦ç¿’å®Ÿè¡Œ
    try:
        max_epochs = config['train']['epoch']
        print(f"ğŸš€ Starting training for {max_epochs} epochs")
        trainer.run(loader_src, max_epochs=max_epochs)
        print("âœ“ Training completed!")
    except Exception as e:
        print(f"Training failed: {e}")
        import traceback
        traceback.print_exc()
    finally:
        wandb.finish()


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', '-c', required=True, type=str)
    parser.add_argument('--fold', '-f', type=int, default=None)
    parser.add_argument('--device', '-d', required=True, type=str)
    parser.add_argument('--parallel', '-p', choices=['DataParallel', 'single'], 
                       default='DataParallel')
    args = parser.parse_args()
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    device_ids, primary_device = utils.parse_devices(args.device)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    config_name = os.path.splitext(os.path.basename(args.config))[0]
    args.out_dir = f'../logs/{config_name}_final_gpu{"_".join(map(str, device_ids))}'
    if args.fold is not None:
        args.out_dir = f"{args.out_dir}_fold{args.fold}"
    
    os.makedirs(args.out_dir, exist_ok=True)
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    config = utils.load_json(args.config)
    utils.save_json(os.path.join(args.out_dir, 'config.json'), config)
    utils.command_log(args.out_dir)
    
    # å®Ÿè¡Œ
    main(args.fold, device_ids, primary_device, args.out_dir, args.parallel, **config)
    utils.save_text(os.path.join(args.out_dir, 'finish.txt'), '')