"""
DANN Training Script - Final Version
"""

import argparse
import os
import torch
import torch.nn as nn
from torch.nn.parallel import DataParallel
import wandb
from ignite.engine import Events, Engine
from ignite.contrib.handlers import ProgressBar
from sklearn.metrics import roc_auc_score  # â†è¿½åŠ 

from domain_discriminator import DomainDiscriminator, DANNClassifier, calculate_lambda_p
import utils
import numpy as np

def create_train_step(classifier, domain_discriminator, optimizer, scheduler, 
                    iter_target, device, config, loader_src):
    """å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—é–¢æ•°ï¼ˆç–¾æ‚£åˆ†é¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½åŠ ç‰ˆï¼‰"""
    cls_criterion = nn.CrossEntropyLoss()
    domain_criterion = nn.BCELoss()
    trade_off = config.get('dann', {}).get('trade_off', 1.0)
    max_epochs = config['train']['epoch']
    
    # å‰å‡¦ç†é–¢æ•°ã‚’äº‹å‰ã«å–å¾—
    _, pre, _, _, _ = utils.get_model_and_processors(config, device)
    
    def train_step(engine, batch):
        classifier.train()
        domain_discriminator.train()
        optimizer.zero_grad()
        
        try:
            # ã‚½ãƒ¼ã‚¹ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒãƒƒãƒã‚’å–å¾—
            x_s, y_s = utils.safe_batch_processing(batch, device, pre, is_evaluation=False)
            target_batch = next(iter_target)
            x_t, _ = utils.safe_batch_processing(target_batch, device, pre, is_evaluation=False)
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å–å¾—
            config_batch_size = config.get('dataset', {}).get('batch_size', 128)
            half_size = config_batch_size // 2  # 64
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            if engine.state.epoch <= 2 and engine.state.iteration <= 3:
                print(f"ğŸ” Batch size debug:")
                print(f"  Config batch_size: {config_batch_size}")
                print(f"  Target half_size: {half_size}")
                if isinstance(x_s, torch.Tensor):
                    print(f"  Source actual size: {x_s.shape[0]}")
                elif isinstance(x_s, dict):
                    sample_tensor = next(iter(x_s.values()))
                    print(f"  Source actual size: {sample_tensor.shape[0]}")
                if isinstance(x_t, torch.Tensor):
                    print(f"  Target actual size: {x_t.shape[0]}")
                elif isinstance(x_t, dict):
                    sample_tensor = next(iter(x_t.values()))
                    print(f"  Target actual size: {sample_tensor.shape[0]}")
            
            # ãƒ‡ãƒ¼ã‚¿ã®å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
            if isinstance(x_s, torch.Tensor):
                actual_source_size = x_s.shape[0]
            elif isinstance(x_s, dict):
                actual_source_size = next(iter(x_s.values())).shape[0]
            else:
                actual_source_size = len(x_s)
            
            if isinstance(x_t, torch.Tensor):
                actual_target_size = x_t.shape[0]
            elif isinstance(x_t, dict):
                actual_target_size = next(iter(x_t.values())).shape[0]
            else:
                actual_target_size = len(x_t)
            
            # â˜… ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®è­¦å‘Š
            if actual_source_size < half_size:
                print(f"âš ï¸ Warning: Source batch too small ({actual_source_size} < {half_size})")
                half_size = min(half_size, actual_source_size)
            
            if actual_target_size < half_size:
                print(f"âš ï¸ Warning: Target batch too small ({actual_target_size} < {half_size})")
                half_size = min(half_size, actual_target_size)
            
            if half_size < 8:  # æœ€å°ãƒãƒƒãƒã‚µã‚¤ã‚ºç¢ºä¿
                print(f"âŒ CRITICAL: Batch size too small: {half_size}")
                print(f"Source: {actual_source_size}, Target: {actual_target_size}")
                raise ValueError(f"Insufficient data for mixed batch: source={actual_source_size}, target={actual_target_size}")
            
            # æ··åˆãƒãƒƒãƒã‚’ä½œæˆï¼ˆã‚½ãƒ¼ã‚¹64 + ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ64 = 128ï¼‰
            if isinstance(x_s, torch.Tensor) and isinstance(x_t, torch.Tensor):
                # ãƒ†ãƒ³ã‚½ãƒ«ã®å ´åˆ
                mixed_x = torch.cat([x_s[:half_size], x_t[:half_size]], dim=0)
                mixed_y_source = y_s[:half_size]
                
            elif isinstance(x_s, dict) and isinstance(x_t, dict):
                # è¾æ›¸ã®å ´åˆ
                mixed_x = {}
                for key in x_s.keys():
                    if key in x_t and hasattr(x_s[key], 'shape') and hasattr(x_t[key], 'shape'):
                        mixed_x[key] = torch.cat([x_s[key][:half_size], x_t[key][:half_size]], dim=0)
                    else:
                        # ã‚­ãƒ¼ãŒä¸€è‡´ã—ãªã„å ´åˆã¯ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ï¼ˆè­¦å‘Šå‡ºåŠ›ï¼‰
                        print(f"âš ï¸ Key '{key}' not found in target, using source data only")
                        mixed_x[key] = x_s[key][:half_size]
                
                mixed_y_source = y_s[:half_size]
            else:
                raise ValueError(f"Incompatible data types: {type(x_s)} and {type(x_t)}")
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆï¼ˆ0: ã‚½ãƒ¼ã‚¹[0:half_size], 1: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ[half_size:2*half_size]ï¼‰
            domain_labels = torch.cat([
                torch.zeros(half_size, 1),  # ã‚½ãƒ¼ã‚¹éƒ¨åˆ†
                torch.ones(half_size, 1)    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéƒ¨åˆ†
            ], dim=0).to(device)
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæˆåŠŸæ™‚ï¼‰
            if engine.state.epoch <= 2 and engine.state.iteration <= 3:
                print(f"âœ“ Mixed batch created successfully:")
                print(f"  Source samples: {half_size} (indices 0:{half_size})")
                print(f"  Target samples: {half_size} (indices {half_size}:{half_size*2})")
                print(f"  Total batch size: {half_size*2}")
                if isinstance(mixed_x, dict):
                    for k, v in mixed_x.items():
                        if hasattr(v, 'shape'):
                            print(f"  {k} shape: {v.shape}")
                else:
                    print(f"  Mixed batch shape: {mixed_x.shape}")
                print(f"  Domain labels shape: {domain_labels.shape}")
            
            # GRLå¼·åº¦èª¿æ•´
            p = float(engine.state.iteration + (engine.state.epoch - 1) * len(loader_src)) / (max_epochs * len(loader_src))
            alpha = 2.0 / (1.0 + np.exp(-10 * p)) - 1.0  # DANNã®æ¨™æº–å¼
            
            # alpha = 1.0  # â˜… ã“ã®è¡Œã‚’å‰Šé™¤
            utils.set_alpha_safely(domain_discriminator, alpha)
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            if engine.state.epoch <= 2 and engine.state.iteration <= 3:
                print(f"  GRL alpha: {alpha:.4f} (dynamic, p={p:.4f})")
            
            # åˆ†é¡å™¨ã§ç‰¹å¾´æŠ½å‡ºã¨åˆ†é¡
            mixed_pred, mixed_features = classifier(mixed_x)
            
            # åˆ†é¡æå¤±ï¼ˆã‚½ãƒ¼ã‚¹éƒ¨åˆ†ã®ã¿ï¼šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹0ã‹ã‚‰half_size-1ï¼‰
            source_pred = mixed_pred[:half_size]
            cls_loss = cls_criterion(source_pred, mixed_y_source)
            
            # â˜… ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥ï¼ˆGRLã‚’é€šã—ã¦å‹¾é…åè»¢ï¼‰
            # domain_discriminatorã®å†…éƒ¨ã§mixed_featuresãŒGRLã‚’é€šéã—ã¦å‹¾é…åè»¢
            domain_pred = domain_discriminator(mixed_features)
            domain_loss = domain_criterion(domain_pred, domain_labels)
            
            # ç·æå¤±ï¼ˆé‡è¦ï¼šdomain_lossã¯GRLã«ã‚ˆã‚Šåˆ†é¡å™¨ã¸ã®å‹¾é…ã‚’åè»¢ï¼‰
            total_loss = cls_loss + trade_off * domain_loss
            
            # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
            # ã“ã“ã§GRLã®å‹¾é…åè»¢ãŒåŠ¹æœã‚’ç™ºæ®ï¼š
            # - cls_lossã®å‹¾é…ï¼šåˆ†é¡å™¨ã‚’ã€Œè‰¯ã„åˆ†é¡ã€æ–¹å‘ã«æ›´æ–°
            # - domain_lossã®å‹¾é…ï¼šGRLã«ã‚ˆã‚Šåˆ†é¡å™¨ã‚’ã€Œãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥å›°é›£ã€æ–¹å‘ã«æ›´æ–°
            total_loss.backward()
            optimizer.step()
            if scheduler is not None:
                scheduler.step()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            with torch.no_grad():
                # â˜… ç–¾æ‚£åˆ†é¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå­¦ç¿’æ™‚ï¼‰
                source_pred_np = source_pred.detach().cpu().numpy()
                mixed_y_source_np = mixed_y_source.detach().cpu().numpy()
                
                # åˆ†é¡ç²¾åº¦
                source_acc = (source_pred.argmax(dim=1) == mixed_y_source).float().mean()
                
                # åˆ†é¡AUC
                try:
                    n_classes = source_pred.shape[1]
                    if n_classes == 2:
                        source_pred_prob = torch.softmax(source_pred, dim=1)[:, 1].detach().cpu().numpy()
                        cls_auc = roc_auc_score(mixed_y_source_np, source_pred_prob)
                    else:
                        source_pred_prob = torch.softmax(source_pred, dim=1).detach().cpu().numpy()
                        cls_auc = roc_auc_score(mixed_y_source_np, source_pred_prob, multi_class='ovr')
                except Exception as e:
                    print(f"âš ï¸ Classification AUC calculation failed: {e}")
                    cls_auc = 0.5
                
                # åˆ†é¡Macro-Sensitivity
                cls_macro_sens = utils.macro_sensitivity(source_pred_np, mixed_y_source_np, source_pred.shape[1])
                
                # â˜… ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå­¦ç¿’æ™‚ï¼‰
                domain_pred_binary = (domain_pred > 0.5).float()
                domain_acc = (domain_pred_binary == domain_labels).float().mean()
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥AUC
                try:
                    domain_pred_np = domain_pred.detach().cpu().numpy().flatten()
                    domain_labels_np = domain_labels.detach().cpu().numpy().flatten()
                    domain_auc = roc_auc_score(domain_labels_np, domain_pred_np)
                except Exception as e:
                    print(f"âš ï¸ Domain AUC calculation failed: {e}")
                    domain_auc = 0.5
            
            return {
                # å…¨ä½“æå¤±
                "loss": total_loss.item(),
                
                # ç–¾æ‚£åˆ†é¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå­¦ç¿’æ™‚ï¼‰
                "cls_loss": cls_loss.item(),
                "cls_acc": source_acc.item(),
                "cls_auc": cls_auc,
                "cls_macro_sensitivity": cls_macro_sens,
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå­¦ç¿’æ™‚ï¼‰
                "domain_loss": domain_loss.item(),
                "domain_acc": domain_acc.item(),
                "domain_auc": domain_auc,
                
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                "alpha": alpha,
                "batch_size": half_size * 2,
                "source_samples": half_size,
                "target_samples": half_size
            }
            
        except Exception as e:
            print(f"âŒ Training step failed: {e}")
            import traceback
            traceback.print_exc()
            raise e
    
    return train_step


def create_evaluation_step(classifier, domain_discriminator, iter_target, device, config):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªè©•ä¾¡ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³æå¤±å«ã‚€ï¼‰"""
    _, pre, _, _, _ = utils.get_model_and_processors(config, device)
    cls_criterion = nn.CrossEntropyLoss()
    domain_criterion = nn.BCELoss()
    trade_off = config.get('dann', {}).get('trade_off', 1.0)
    
    def evaluation_step(engine, batch):
        classifier.eval()
        domain_discriminator.eval()
        
        with torch.no_grad():
            try:
                # ã‚½ãƒ¼ã‚¹ãƒãƒƒãƒå‡¦ç†
                x_s, y_s = utils.safe_batch_processing(batch, device, pre, is_evaluation=True)
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒå–å¾—
                target_batch = next(iter_target)
                x_t, _ = utils.safe_batch_processing(target_batch, device, pre, is_evaluation=True)
                
                # ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´
                batch_size = min(
                    x_s.shape[0] if isinstance(x_s, torch.Tensor) else next(iter(x_s.values())).shape[0],
                    x_t.shape[0] if isinstance(x_t, torch.Tensor) else next(iter(x_t.values())).shape[0]
                )
                
                # ã‚½ãƒ¼ã‚¹ã®ä¸€éƒ¨ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ä¸€éƒ¨ã‚’æ··åˆ
                if isinstance(x_s, dict) and isinstance(x_t, dict):
                    mixed_x = {}
                    for key in x_s.keys():
                        if key in x_t:
                            mixed_x[key] = torch.cat([
                                x_s[key][:batch_size//2],
                                x_t[key][:batch_size//2]
                            ], dim=0)
                        else:
                            mixed_x[key] = x_s[key][:batch_size//2]
                elif isinstance(x_s, torch.Tensor) and isinstance(x_t, torch.Tensor):
                    mixed_x = torch.cat([x_s[:batch_size//2], x_t[:batch_size//2]], dim=0)
                else:
                    # å‹ãŒä¸€è‡´ã—ãªã„å ´åˆã¯ã‚½ãƒ¼ã‚¹ã®ã¿
                    mixed_x = x_s
                    batch_size = x_s.shape[0] if isinstance(x_s, torch.Tensor) else next(iter(x_s.values())).shape[0]
                
                # åˆ†é¡å™¨ã§äºˆæ¸¬
                if isinstance(mixed_x, dict) and len(mixed_x) > len(x_s) if isinstance(x_s, dict) else True:
                    # æ··åˆãƒãƒƒãƒã®å ´åˆ
                    mixed_pred, mixed_features = classifier(mixed_x)
                    source_pred = mixed_pred[:batch_size//2]
                    source_y = y_s[:batch_size//2]
                    
                    # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ©ãƒ™ãƒ«ä½œæˆ
                    domain_labels = torch.cat([
                        torch.zeros(batch_size//2, 1),  # ã‚½ãƒ¼ã‚¹
                        torch.ones(batch_size//2, 1)    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
                    ], dim=0).to(device)
                    
                    # ãƒ‰ãƒ¡ã‚¤ãƒ³æå¤±è¨ˆç®—
                    domain_pred = domain_discriminator(mixed_features)
                    domain_loss = domain_criterion(domain_pred, domain_labels)
                else:
                    # ã‚½ãƒ¼ã‚¹ã®ã¿ã®å ´åˆ
                    source_pred, mixed_features = classifier(x_s)
                    source_y = y_s
                    domain_loss = torch.tensor(0.0).to(device)
                
                # åˆ†é¡æå¤±è¨ˆç®—
                cls_loss = cls_criterion(source_pred, source_y)
                total_loss = cls_loss + trade_off * domain_loss
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
                cls_acc = (source_pred.argmax(dim=1) == source_y).float().mean()
                
                # AUCè¨ˆç®—
                try:
                    n_classes = source_pred.shape[1]
                    source_pred_prob = torch.softmax(source_pred, dim=1)
                    
                    if n_classes == 2:
                        auc = roc_auc_score(source_y.cpu().numpy(), source_pred_prob[:, 1].cpu().numpy())
                    else:
                        auc = roc_auc_score(source_y.cpu().numpy(), source_pred_prob.cpu().numpy(), multi_class='ovr')
                except Exception as e:
                    print(f"âš ï¸ AUC calculation failed: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚æ”¹å–„
                    auc = 0.5
                
                return {
                    "cls_loss": cls_loss.item(),
                    "domain_loss": domain_loss.item(),
                    "total_loss": total_loss.item(),
                    "cls_accuracy": cls_acc.item(),
                    "cls_auc": auc,
                    "cls_macro_sensitivity": utils.macro_sensitivity(
                        source_pred.cpu().numpy(), source_y.cpu().numpy(), source_pred.shape[1]
                    )
                }
                
            except Exception as e:
                print(f"âŒ Evaluation step failed: {e}")
                return {
                    "cls_loss": 1.0, "domain_loss": 1.0, "total_loss": 2.0,
                    "cls_accuracy": 0.0, "cls_auc": 0.5, "cls_macro_sensitivity": 0.0
                }
    
    return evaluation_step


def create_domain_evaluation_step(domain_discriminator, iter_target, device, config):
    """ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥å°‚ç”¨è©•ä¾¡ã‚¹ãƒ†ãƒƒãƒ—"""
    # å‰å‡¦ç†é–¢æ•°ã‚’äº‹å‰ã«å–å¾—
    _, pre, _, _, _ = utils.get_model_and_processors(config, device)
    domain_criterion = nn.BCELoss()
    
    def domain_evaluation_step(source_features, source_batch_size):
        """ã‚½ãƒ¼ã‚¹ç‰¹å¾´ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹å¾´ã§ãƒ‰ãƒ¡ã‚¤ãƒ³AUCè©•ä¾¡"""
        domain_discriminator.eval()
        with torch.no_grad():
            try:
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒã‚’å–å¾—
                target_batch = next(iter_target)
                x_t, _ = utils.safe_batch_processing(target_batch, device, pre, is_evaluation=True)
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹å¾´ã‚’æŠ½å‡ºï¼ˆåˆ†é¡å™¨ã¯evalãƒ¢ãƒ¼ãƒ‰ã®ã¾ã¾ï¼‰
                if hasattr(domain_discriminator, 'module'):
                    # DataParallel ã®å ´åˆã€åˆ†é¡å™¨ã‚’å–å¾—
                    classifier = domain_discriminator.module.classifier if hasattr(domain_discriminator.module, 'classifier') else None
                else:
                    classifier = domain_discriminator.classifier if hasattr(domain_discriminator, 'classifier') else None
                
                if classifier is None:
                    # åˆ†é¡å™¨ã¸ã®å‚ç…§ãŒãªã„å ´åˆã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‹ã‚‰å–å¾—ï¼ˆãƒˆãƒªãƒƒã‚­ãƒ¼ï¼‰
                    print("âš ï¸ Warning: Cannot access classifier from domain_discriminator")
                    return 0.5, 0.5, 1.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                
                _, target_features = classifier(x_t)
                
                # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’çµ±ä¸€
                min_size = min(source_batch_size, target_features.shape[0])
                source_features_eval = source_features[:min_size]
                target_features_eval = target_features[:min_size]
                
                # æ··åˆç‰¹å¾´ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ©ãƒ™ãƒ«
                mixed_features = torch.cat([source_features_eval, target_features_eval], dim=0)
                domain_labels = torch.cat([
                    torch.zeros(min_size, 1),  # ã‚½ãƒ¼ã‚¹
                    torch.ones(min_size, 1)    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
                ], dim=0).to(device)
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥
                domain_pred = domain_discriminator(mixed_features)
                domain_acc = ((domain_pred > 0.5).float() == domain_labels).float().mean()
                domain_loss = domain_criterion(domain_pred, domain_labels)
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥AUC
                try:
                    domain_pred_np = domain_pred.detach().cpu().numpy().flatten()
                    domain_labels_np = domain_labels.detach().cpu().numpy().flatten()
                    domain_auc = roc_auc_score(domain_labels_np, domain_pred_np)
                except Exception as e:
                    print(f"âš ï¸ Domain AUC calculation failed: {e}")
                    domain_auc = 0.5
                
                return domain_auc, domain_acc.item(), domain_loss.item()
                
            except Exception as e:
                print(f"âŒ Domain evaluation failed: {e}")
                return 0.5, 0.5, 1.0
    
    return domain_evaluation_step


def main(fold, device_ids, primary_device, out_dir, parallel_mode, **config):
    """ãƒ¡ã‚¤ãƒ³å­¦ç¿’é–¢æ•°"""
    
    print(f"ğŸš€ Starting DANN Training")
    print(f"Device IDs: {device_ids}, Primary: {primary_device}")
    
    # åˆæœŸåŒ–
    wandb.init(
        project="ResNet18_DANN_final",
        name=f"dann_fold{fold}" if fold is not None else "dann_holdout",
        config=config,
        dir=out_dir,
        tags=["dann", "final"]
    )
    
    # CUDAç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    torch.cuda.set_device(primary_device)
    g = utils.setup_cuda_environment(device_ids, config['train']['seed'])
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
    print(f"ğŸ“‚ Loading datasets...")
    loader_src, loader_eval_tr, loader_eval_vl, loader_target = utils.get_datasets(config, fold, g)
    iter_target = utils.ForeverDataIterator(loader_target)
    
    # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    print(f"ğŸ—ï¸ Building models...")
    backbone, pre, post, func, met = utils.get_model_and_processors(config, primary_device)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒã§ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã®ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰
    print(f"ğŸ” Checking backbone compatibility...")
    sample_batch = next(iter(loader_src))
    x_sample, y_sample = utils.safe_batch_processing(sample_batch, primary_device, pre, is_evaluation=False)
    
    print(f"Sample input type: {type(x_sample)}")
    if isinstance(x_sample, dict):
        print(f"Sample input keys: {list(x_sample.keys())}")
        for k, v in x_sample.items():
            if hasattr(v, 'shape'):
                print(f"  {k} shape: {v.shape}")
    else:
        print(f"Sample input shape: {x_sample.shape}")
    
    # DANNè¨­å®š
    num_classes = config['model']['n_class']
    bottleneck_dim = config.get('dann', {}).get('bottleneck_dim', 256)
    domain_hidden = config.get('dann', {}).get('domain_hidden_size', 1024)
    
    print(f"ğŸ“Š DANN Configuration:")
    print(f"  Num classes: {num_classes}")
    print(f"  Bottleneck dim: {bottleneck_dim}")
    print(f"  Domain hidden: {domain_hidden}")
    
    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    classifier = DANNClassifier(backbone, num_classes, bottleneck_dim).to(primary_device)
    domain_discriminator = DomainDiscriminator(
        initial_feature_dim=bottleneck_dim,
        hidden_dim=domain_hidden
    ).to(primary_device)
    
    # GPUä¸¦åˆ—åŒ–
    if len(device_ids) > 1 and parallel_mode == 'DataParallel':
        classifier = DataParallel(classifier, device_ids=device_ids)
        domain_discriminator = DataParallel(domain_discriminator, device_ids=device_ids)
        print(f"âœ“ Using DataParallel on GPUs: {device_ids}")
    
    # æœ€é©åŒ–è¨­å®š
    all_params = list(classifier.parameters()) + list(domain_discriminator.parameters())
    optimizer = utils.init_optimizer(all_params, config)
    scheduler = utils.get_scheduler(optimizer, config)
    
    # ã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆ
    train_step = create_train_step(classifier, domain_discriminator, optimizer, scheduler,iter_target, primary_device, config, loader_src)
    trainer = Engine(train_step)
    
    # è©•ä¾¡ã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆï¼ˆä¿®æ­£ç‰ˆï¼‰
    evaluation_step = create_evaluation_step(classifier, domain_discriminator, iter_target, primary_device, config)
    domain_evaluation_step = create_domain_evaluation_step(domain_discriminator, iter_target, primary_device, config)
    eval_tr = Engine(evaluation_step)
    eval_vl = Engine(evaluation_step)
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    pbar = ProgressBar()
    pbar.attach(trainer, output_transform=lambda x: {'loss': x['loss']})
    
    # ãƒ­ã‚°å‡¦ç†ï¼ˆä¿®æ­£ç‰ˆï¼šæ­£ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³AUCè¨ˆç®—ï¼‰
    @trainer.on(Events.EPOCH_COMPLETED)
    def log_results(engine):
        out = engine.state.output
        
        print(f"Epoch {engine.state.epoch:3d} - "
              f"Loss: {out['loss']:.4f} "
              f"(Cls: {out['cls_loss']:.4f}, Domain: {out['domain_loss']:.4f}) | "
              f"Alpha: {out['alpha']:.4f}")
        
        # è©•ä¾¡å®Ÿè¡Œ
        try:
            classifier.eval()
            domain_discriminator.eval()
            
            # Trainè©•ä¾¡
            eval_tr.run(loader_eval_tr, max_epochs=1)
            train_eval = eval_tr.state.output
            
            # Validationè©•ä¾¡
            eval_vl.run(loader_eval_vl, max_epochs=1)
            val_eval = eval_vl.state.output
            
            # å­¦ç¿’çŠ¶æ³ã‚’ãƒ—ãƒªãƒ³ãƒˆ
            print(f"  Train Eval - Loss: {train_eval['total_loss']:.4f}, "
                  f"Acc: {train_eval['cls_accuracy']:.3f}, AUC: {train_eval['cls_auc']:.3f}")
            print(f"  Val Eval   - Loss: {val_eval['total_loss']:.4f}, "
                  f"Acc: {val_eval['cls_accuracy']:.3f}, AUC: {val_eval['cls_auc']:.3f}")
            
            # wandbãƒ­ã‚°
            wandb.log({
                "epoch": engine.state.epoch,
                # è¨“ç·´æ™‚
                "train/loss": out['loss'],
                "train/cls_loss": out['cls_loss'],
                "train/domain_loss": out['domain_loss'],
                "train/cls_acc": out['cls_acc'],
                "train/alpha": out['alpha'],
                
                # è©•ä¾¡æ™‚
                "train_eval/total_loss": train_eval['total_loss'],
                "train_eval/cls_acc": train_eval['cls_accuracy'],
                "train_eval/cls_auc": train_eval['cls_auc'],
                
                "val/total_loss": val_eval['total_loss'],
                "val/cls_acc": val_eval['cls_accuracy'],
                "val/cls_auc": val_eval['cls_auc'],
            })
            
            classifier.train()
            domain_discriminator.train()
            
        except Exception as e:
            print(f"âš ï¸ Evaluation failed: {e}")
    
    # å­¦ç¿’å®Ÿè¡Œ
    try:
        max_epochs = config['train']['epoch']
        print(f"ğŸš€ Starting training for {max_epochs} epochs")
        trainer.run(loader_src, max_epochs=max_epochs)
        print("âœ“ Training completed!")
    except Exception as e:
        print(f"Training failed: {e}")
        import traceback
        traceback.print_exc()
    finally:
        wandb.finish()


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', '-c', required=True, type=str)
    parser.add_argument('--fold', '-f', type=int, default=None)
    parser.add_argument('--device', '-d', required=True, type=str)
    parser.add_argument('--parallel', '-p', choices=['DataParallel', 'single'], 
                       default='DataParallel')
    args = parser.parse_args()
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    device_ids, primary_device = utils.parse_devices(args.device)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    config_name = os.path.splitext(os.path.basename(args.config))[0]
    args.out_dir = f'../logs/{config_name}_final_gpu{"_".join(map(str, device_ids))}'
    if args.fold is not None:
        args.out_dir = f"{args.out_dir}_fold{args.fold}"
    
    os.makedirs(args.out_dir, exist_ok=True)
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    config = utils.load_json(args.config)
    utils.save_json(os.path.join(args.out_dir, 'config.json'), config)
    utils.command_log(args.out_dir)
    
    # å®Ÿè¡Œ
    main(args.fold, device_ids, primary_device, args.out_dir, args.parallel, **config)
    utils.save_text(os.path.join(args.out_dir, 'finish.txt'), '')