"""
DANN Training Script - resnet18_baseå¯¾å¿œç‰ˆ
"""

import argparse
import os
import torch
import torch.nn as nn
from torch.nn.parallel import DataParallel
import wandb
from ignite.engine import Events, Engine
from ignite.contrib.handlers import ProgressBar
from sklearn.metrics import roc_auc_score

from domain_discriminator import DomainDiscriminator, DANNClassifier, calculate_lambda_p
import utils
import numpy as np


def create_train_step(classifier, domain_discriminator, optimizer, scheduler, 
                     iter_target, device, config, loader_src):
    """DANNå­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆresnet18_baseå¯¾å¿œï¼‰"""
    cls_criterion = nn.CrossEntropyLoss()
    domain_criterion = nn.BCELoss()
    max_epochs = config['train']['epoch']
    
    # å‰å‡¦ç†é–¢æ•°ã‚’å–å¾—
    _, pre, _, _, _ = utils.get_model_and_processors(config, device)
    
    def train_step(engine, batch):
        classifier.train()
        domain_discriminator.train()
        optimizer.zero_grad()
        
        try:
            # ã‚½ãƒ¼ã‚¹ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
            x_s, y_s = utils.safe_batch_processing(batch, device, pre, is_evaluation=False)
            target_batch = next(iter_target)
            x_t, _ = utils.safe_batch_processing(target_batch, device, pre, is_evaluation=False)
            
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´
            batch_size = min(x_s.shape[0], x_t.shape[0])
            half_size = batch_size // 2
            
            if half_size < 8:
                raise ValueError(f"Batch size too small: {batch_size}")
            
            # æ··åˆãƒãƒƒãƒä½œæˆï¼ˆresnet18_baseã¯ãƒ†ãƒ³ã‚½ãƒ«å…¥åŠ›ï¼‰
            mixed_x = torch.cat([x_s[:half_size], x_t[:half_size]], dim=0)
            mixed_y_source = y_s[:half_size]
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ©ãƒ™ãƒ«ï¼ˆ0: ã‚½ãƒ¼ã‚¹, 1: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰
            domain_labels = torch.cat([
                torch.zeros(half_size, 1),
                torch.ones(half_size, 1)
            ], dim=0).to(device)
            
            # GRLå¼·åº¦ã‚’å‹•çš„èª¿æ•´ï¼ˆDANNè«–æ–‡ã«å¾“ã£ã¦ï¼‰
            p = float(engine.state.iteration + (engine.state.epoch - 1) * len(loader_src)) / (max_epochs * len(loader_src))
            alpha = 2.0 / (1.0 + np.exp(-10 * p)) - 1.0
            
            # alphaå€¤ã‚’ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥å™¨ã«è¨­å®š
            utils.set_alpha_safely(domain_discriminator, alpha)
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆåˆæœŸã‚¨ãƒãƒƒã‚¯ã®ã¿ï¼‰
            if engine.state.epoch <= 2 and engine.state.iteration <= 3:
                print(f"ğŸ” Training step debug:")
                print(f"  Mixed batch shape: {mixed_x.shape}")
                print(f"  Domain labels shape: {domain_labels.shape}")
                print(f"  GRL alpha: {alpha:.4f} (p={p:.4f})")
            
            # åˆ†é¡å™¨ã§forwardï¼ˆç‰¹å¾´æŠ½å‡º+åˆ†é¡ï¼‰
            mixed_pred, mixed_features = classifier(mixed_x)
            
            # åˆ†é¡æå¤±ï¼ˆã‚½ãƒ¼ã‚¹éƒ¨åˆ†ã®ã¿ï¼‰
            source_pred = mixed_pred[:half_size]
            cls_loss = cls_criterion(source_pred, mixed_y_source)
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥ï¼ˆmixed_featuresãŒGRLã‚’é€šã£ã¦å‹¾é…åè»¢ï¼‰
            domain_pred = domain_discriminator(mixed_features)
            domain_loss = domain_criterion(domain_pred, domain_labels)
            
            # ç·æå¤±
            total_loss = cls_loss +  domain_loss
            
            # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
            total_loss.backward()
            
            # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼ˆå®‰å®šåŒ–ï¼‰
            torch.nn.utils.clip_grad_norm_(classifier.parameters(), 1.0)
            torch.nn.utils.clip_grad_norm_(domain_discriminator.parameters(), 1.0)
            
            optimizer.step()
            if scheduler is not None:
                scheduler.step()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            with torch.no_grad():
                # åˆ†é¡ç²¾åº¦
                source_acc = (source_pred.argmax(dim=1) == mixed_y_source).float().mean()
                
                # åˆ†é¡AUC
                try:
                    if source_pred.shape[1] == 2:
                        source_pred_prob = torch.softmax(source_pred, dim=1)[:, 1].cpu().numpy()
                        cls_auc = roc_auc_score(mixed_y_source.cpu().numpy(), source_pred_prob)
                    else:
                        source_pred_prob = torch.softmax(source_pred, dim=1).cpu().numpy()
                        cls_auc = roc_auc_score(mixed_y_source.cpu().numpy(), source_pred_prob, multi_class='ovr')
                except:
                    cls_auc = 0.5
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥ç²¾åº¦
                domain_acc = ((domain_pred > 0.5).float() == domain_labels).float().mean()
                
                # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥AUC
                try:
                    domain_auc = roc_auc_score(
                        domain_labels.cpu().numpy().flatten(),
                        domain_pred.cpu().numpy().flatten()
                    )
                except:
                    domain_auc = 0.5
            
            return {
                "loss": total_loss.item(),
                "cls_loss": cls_loss.item(),
                "domain_loss": domain_loss.item(),
                "cls_acc": source_acc.item(),
                "cls_auc": cls_auc,
                "domain_acc": domain_acc.item(),
                "domain_auc": domain_auc,
                "alpha": alpha,
            }
            
        except Exception as e:
            print(f"âŒ Training step failed: {e}")
            import traceback
            traceback.print_exc()
            raise e
    
    return train_step


def create_evaluation_step(classifier, domain_discriminator, loader_target, device, config):
    """ä¿®æ­£ç‰ˆï¼šè©•ä¾¡ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆGRLé©ç”¨åˆ¶å¾¡ä»˜ãï¼‰"""
    _, pre, _, _, _ = utils.get_model_and_processors(config, device)
    cls_criterion = nn.CrossEntropyLoss()
    domain_criterion = nn.BCELoss()
    
    def evaluation_step(engine, batch):
        classifier.eval()
        domain_discriminator.eval()
        
        with torch.no_grad():
            try:
                # ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å‡¦ç†
                x_s, y_s = utils.safe_batch_processing(batch, device, pre, is_evaluation=True)
                source_pred, source_features = classifier(x_s)
                cls_loss = cls_criterion(source_pred, y_s)
                source_cls_acc = (source_pred.argmax(dim=1) == y_s).float().mean()
                
                # AUCè¨ˆç®—
                try:
                    if source_pred.shape[1] == 2:
                        source_pred_prob = torch.softmax(source_pred, dim=1)[:, 1].cpu().numpy()
                        source_auc = roc_auc_score(y_s.cpu().numpy(), source_pred_prob)
                    else:
                        source_pred_prob = torch.softmax(source_pred, dim=1).cpu().numpy()
                        source_auc = roc_auc_score(y_s.cpu().numpy(), source_pred_prob, multi_class='ovr')
                except:
                    source_auc = 0.5
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
                try:
                    target_batch = next(loader_target)
                    x_t, _ = utils.safe_batch_processing(target_batch, device, pre, is_evaluation=True)
                    
                    min_batch_size = min(x_s.shape[0], x_t.shape[0])
                    x_s_eval = x_s[:min_batch_size]
                    x_t_eval = x_t[:min_batch_size]
                    y_s_eval = y_s[:min_batch_size]
                    
                    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹å¾´æŠ½å‡º
                    target_pred, target_features = classifier(x_t_eval)
                    
                    # â˜… é‡è¦ï¼šè©•ä¾¡æ™‚ã‚‚è¨“ç·´æ™‚ã¨åŒã˜æ¡ä»¶ã§ãƒ‰ãƒ¡ã‚¤ãƒ³è©•ä¾¡
                    mixed_features = torch.cat([source_features[:min_batch_size], target_features], dim=0)
                    domain_labels = torch.cat([
                        torch.zeros(min_batch_size, 1),
                        torch.ones(min_batch_size, 1)
                    ], dim=0).to(device)
                    
                    # â˜… è©•ä¾¡æ™‚ã‚‚GRLã®ç¾åœ¨ã®alphaå€¤ã‚’ä½¿ç”¨
                    # alphaã‚’ç¾åœ¨ã®è¨“ç·´é€²è¡Œåº¦ã«åŸºã¥ã„ã¦è¨ˆç®—
                    if hasattr(engine, 'state') and hasattr(engine.state, 'epoch'):
                        current_epoch = engine.state.epoch
                        max_epochs = config['train']['epoch']
                        loader_size = 6  # loader_eval_trã®ã‚µã‚¤ã‚º
                        
                        # è¨“ç·´ã¨åŒã˜alphaè¨ˆç®—
                        p = float(current_epoch) / max_epochs
                        eval_alpha = 2.0 / (1.0 + np.exp(-10 * p)) - 1.0
                        
                        # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥å™¨ã«alphaè¨­å®š
                        utils.set_alpha_safely(domain_discriminator, eval_alpha)
                        
                        print(f"  ğŸ“Š Evaluation alpha: {eval_alpha:.4f} (epoch {current_epoch})")
                    
                    # ãƒ‰ãƒ¡ã‚¤ãƒ³è­˜åˆ¥äºˆæ¸¬ï¼ˆGRLé©ç”¨ï¼‰
                    domain_pred = domain_discriminator(mixed_features)
                    domain_loss = domain_criterion(domain_pred, domain_labels)
                    
                    # ãƒ‰ãƒ¡ã‚¤ãƒ³æ€§èƒ½è¨ˆç®—
                    domain_acc = ((domain_pred > 0.5).float() == domain_labels).float().mean()
                    
                    try:
                        domain_auc = roc_auc_score(
                            domain_labels.cpu().numpy().flatten(),
                            domain_pred.cpu().numpy().flatten()
                        )
                    except:
                        domain_auc = 0.5
                        
                except Exception as target_error:
                    print(f"âš ï¸ Target evaluation failed: {target_error}")
                    domain_labels = torch.zeros(x_s.shape[0], 1).to(device)
                    domain_pred = domain_discriminator(source_features)
                    domain_loss = domain_criterion(domain_pred, domain_labels)
                    domain_acc = ((domain_pred > 0.5).float() == domain_labels).float().mean()
                    domain_auc = 0.5
                
                # ç·æå¤±
                total_loss = cls_loss + domain_loss
                
                # Macro sensitivity
                try:
                    cls_macro_sensitivity = utils.macro_sensitivity(
                        source_pred.cpu().numpy(), y_s.cpu().numpy(), source_pred.shape[1]
                    )
                except:
                    cls_macro_sensitivity = 0.0
                
                return {
                    "cls_loss": cls_loss.item(),
                    "cls_accuracy": source_cls_acc.item(),
                    "cls_auc": source_auc,
                    "cls_macro_sensitivity": cls_macro_sensitivity,
                    "domain_loss": domain_loss.item(),
                    "domain_accuracy": domain_acc.item(),
                    "domain_auc": domain_auc,
                    "total_loss": total_loss.item(),
                }
                
            except Exception as e:
                print(f"âŒ Evaluation step failed: {e}")
                return {
                    "cls_loss": 1.0,
                    "cls_accuracy": 0.0,
                    "cls_auc": 0.5,
                    "cls_macro_sensitivity": 0.0,
                    "domain_loss": 1.0,
                    "domain_accuracy": 0.5,  # â† ãƒ©ãƒ³ãƒ€ãƒ ãƒ¬ãƒ™ãƒ«
                    "domain_auc": 0.5,       # â† ãƒ©ãƒ³ãƒ€ãƒ ãƒ¬ãƒ™ãƒ«
                    "total_loss": 2.0,
                }
    
    return evaluation_step


def main(fold, device_ids, primary_device, out_dir, parallel_mode, **config):
    """ãƒ¡ã‚¤ãƒ³å­¦ç¿’é–¢æ•°"""
    
    print(f"ğŸš€ Starting DANN Training (resnet18_base)")
    print(f"Device: {primary_device}, Parallel: {parallel_mode}")
    
    # Weights & BiasesåˆæœŸåŒ–
    wandb.init(
        project="ResNet18_DANN_base",
        name=f"dann_base_fold{fold}" if fold is not None else "dann_base_holdout",
        config=config,
        dir=out_dir,
        tags=["dann", "resnet18_base"]
    )
    
    # CUDAç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    torch.cuda.set_device(primary_device)
    g = utils.setup_cuda_environment(device_ids, config['train']['seed'])
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
    print(f"ğŸ“‚ Loading datasets...")
    loader_src, loader_eval_tr, loader_eval_vl, loader_target = utils.get_datasets(config, fold, g)
    iter_target = utils.ForeverDataIterator(loader_target)
    
    print(f"  Source train batches: {len(loader_src)}")
    print(f"  Target train batches: {len(loader_target)}")
    print(f"  Source eval batches: {len(loader_eval_tr)}")
    print(f"  Source val batches: {len(loader_eval_vl)}")
    
    # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    print(f"ğŸ—ï¸ Building models...")
    backbone, pre, post, func, met = utils.get_model_and_processors(config, primary_device)
    
    # ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ç¢ºèª
    print(f"  Backbone type: {type(backbone).__name__}")
    print(f"  Has feature method: {hasattr(backbone, 'feature')}")
    
    # ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ†ã‚¹ãƒˆ
    try:
        sample_batch = next(iter(loader_src))
        x_sample, y_sample = utils.safe_batch_processing(sample_batch, primary_device, pre, is_evaluation=False)
        print(f"  Sample input shape: {x_sample.shape}")
        
        with torch.no_grad():
            features = backbone.feature(x_sample[:2])  # 2ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ†ã‚¹ãƒˆ
            print(f"  âœ“ Backbone feature output: {features.shape}")
    except Exception as e:
        print(f"  âŒ Backbone test failed: {e}")
        return
    
    # DANNè¨­å®š
    num_classes = config['model']['n_class']
    bottleneck_dim = config.get('dann', {}).get('bottleneck_dim', 256)
    domain_hidden = config.get('dann', {}).get('domain_hidden_size', 1024)
    
    print(f"ğŸ“Š DANN Configuration:")
    print(f"  Num classes: {num_classes}")
    print(f"  Bottleneck dim: {bottleneck_dim}")
    print(f"  Domain hidden: {domain_hidden}")
    
    # DANNãƒ¢ãƒ‡ãƒ«ä½œæˆ
    classifier = DANNClassifier(backbone, num_classes, bottleneck_dim).to(primary_device)
    domain_discriminator = DomainDiscriminator(
        feature_dim=bottleneck_dim,
        hidden_dim=domain_hidden
    ).to(primary_device)
    
    # GPUä¸¦åˆ—åŒ–
    if len(device_ids) > 1 and parallel_mode == 'DataParallel':
        classifier = DataParallel(classifier, device_ids=device_ids)
        domain_discriminator = DataParallel(domain_discriminator, device_ids=device_ids)
        print(f"âœ“ Using DataParallel on GPUs: {device_ids}")
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼è¨­å®š
    all_params = list(classifier.parameters()) + list(domain_discriminator.parameters())
    optimizer = utils.init_optimizer(all_params, config)
    scheduler = utils.get_scheduler(optimizer, config)
    
    print(f"  Optimizer: {optimizer.__class__.__name__}")
    print(f"  Learning rate: {optimizer.param_groups[0]['lr']}")
    print(f"  Scheduler: {scheduler.__class__.__name__ if scheduler else 'None'}")
    
    # ã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆ
    train_step = create_train_step(classifier, domain_discriminator, optimizer, scheduler,
                                  iter_target, primary_device, config, loader_src)
    trainer = Engine(train_step)
    
    # è©•ä¾¡ã‚¨ãƒ³ã‚¸ãƒ³
    evaluation_step = create_evaluation_step(classifier, domain_discriminator, iter_target, primary_device, config)
    eval_tr = Engine(evaluation_step)
    eval_vl = Engine(evaluation_step)
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    pbar = ProgressBar()
    pbar.attach(trainer, output_transform=lambda x: {'loss': f"{x['loss']:.4f}"})
    
    def safe_get(eval_dict, key, default=0.0):
        """è¾æ›¸ã‹ã‚‰å®‰å…¨ã«ã‚­ãƒ¼ã‚’å–å¾—"""
        if eval_dict and isinstance(eval_dict, dict) and key in eval_dict:
            return eval_dict[key]
        else:
            print(f"âš ï¸ Key '{key}' not found in evaluation result")
            return default


    # ãƒ­ã‚°å‡¦ç†
    @trainer.on(Events.EPOCH_COMPLETED)
    def log_results(engine):
        out = engine.state.output
        epoch = engine.state.epoch
        
        print(f"Epoch {epoch:3d} - "
              f"Loss: {out['loss']:.4f} "
              f"(Cls: {out['cls_loss']:.4f}, Domain: {out['domain_loss']:.4f}) | "
              f"Alpha: {out['alpha']:.4f}, Domain Acc: {out['domain_acc']:.3f}")
        
        # è©•ä¾¡å®Ÿè¡Œï¼ˆä¿®æ­£ç‰ˆï¼‰
        try:
            classifier.eval()
            domain_discriminator.eval()
            
            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³è©•ä¾¡å«ã‚€ï¼‰
            print("  ğŸ” Running training evaluation...")
            eval_tr.run(loader_eval_tr, max_epochs=1)
            train_eval = eval_tr.state.output
            
            # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³è©•ä¾¡å«ã‚€ï¼‰
            print("  ğŸ” Running validation evaluation...")
            eval_vl.run(loader_eval_vl, max_epochs=1)
            val_eval = eval_vl.state.output
            
            # çµæœè¡¨ç¤ºï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³æ€§èƒ½ã‚‚å«ã‚€ï¼‰
            print(f"  Train - Loss: {safe_get(train_eval, 'total_loss', 1.0):.4f}, "
                  f"Cls Acc: {safe_get(train_eval, 'cls_accuracy', 0.0):.3f}, "
                  f"Domain Acc: {safe_get(train_eval, 'domain_accuracy', 0.5):.3f}")
            
            print(f"  Val   - Loss: {safe_get(val_eval, 'total_loss', 1.0):.4f}, "
                  f"Cls Acc: {safe_get(val_eval, 'cls_accuracy', 0.0):.3f}, "
                  f"Domain Acc: {safe_get(val_eval, 'domain_accuracy', 0.5):.3f}")
            
            # æ‹¡å¼µWandBãƒ­ã‚°
            wandb_log = {
                "epoch": epoch,
                
                # è¨“ç·´æ™‚ãƒ¡ãƒˆãƒªã‚¯ã‚¹  
                "train/total_loss": out['loss'],
                "train/cls_loss": out['cls_loss'],
                "train/domain_loss": out['domain_loss'],
                "train/cls_acc": out['cls_acc'],
                "train/cls_auc": out['cls_auc'],
                "train/domain_acc": out['domain_acc'],
                "train/domain_auc": out['domain_auc'],
                "train/alpha": out['alpha'],
                
                # è¨“ç·´è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
                "train_eval/total_loss": safe_get(train_eval, 'total_loss', 1.0),
                "train_eval/cls_acc": safe_get(train_eval, 'cls_accuracy', 0.0),
                "train_eval/cls_auc": safe_get(train_eval, 'cls_auc', 0.5),
                "train_eval/domain_acc": safe_get(train_eval, 'domain_accuracy', 0.5),
                "train_eval/domain_auc": safe_get(train_eval, 'domain_auc', 0.5),
                
                # æ¤œè¨¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹  
                "val/total_loss": safe_get(val_eval, 'total_loss', 1.0),
                "val/cls_acc": safe_get(val_eval, 'cls_accuracy', 0.0),
                "val/cls_auc": safe_get(val_eval, 'cls_auc', 0.5),
                "val/domain_acc": safe_get(val_eval, 'domain_accuracy', 0.5),
                "val/domain_auc": safe_get(val_eval, 'domain_auc', 0.5),
            }
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†é¡æ€§èƒ½ï¼ˆåˆ©ç”¨å¯èƒ½æ™‚ï¼‰
            if train_eval and 'target_cls_accuracy' in train_eval:
                wandb_log["train_eval/target_cls_acc"] = train_eval['target_cls_accuracy']
            if val_eval and 'target_cls_accuracy' in val_eval:
                wandb_log["val/target_cls_acc"] = val_eval['target_cls_accuracy']
            
            wandb.log(wandb_log)
            
            classifier.train()
            domain_discriminator.train()
            
        except Exception as e:
            print(f"âš ï¸ Evaluation failed: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®æœ€å°é™ãƒ­ã‚°
            try:
                wandb.log({
                    "epoch": epoch,
                    "train/total_loss": out['loss'],
                    "train/cls_loss": out['cls_loss'],
                    "train/domain_loss": out['domain_loss'],
                    "train/cls_acc": out['cls_acc'],
                    "train/alpha": out['alpha'],
                })
            except:
                pass
    
    # å­¦ç¿’å®Ÿè¡Œ
    try:
        max_epochs = config['train']['epoch']
        print(f"ğŸš€ Starting training for {max_epochs} epochs")
        print("=" * 80)
        
        trainer.run(loader_src, max_epochs=max_epochs)
        
        print("=" * 80)
        print("âœ“ Training completed successfully!")
        
    except Exception as e:
        print(f"âŒ Training failed: {e}")
        import traceback
        traceback.print_exc()
    finally:
        wandb.finish()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='DANN Training with resnet18_base')
    parser.add_argument('--config', '-c', required=True, type=str, help='Config file path')
    parser.add_argument('--fold', '-f', type=int, default=None, help='Fold number for cross-validation')
    parser.add_argument('--device', '-d', required=True, type=str, help='CUDA device(s)')
    parser.add_argument('--parallel', '-p', choices=['DataParallel', 'single'], 
                       default='single', help='Parallelization method')
    args = parser.parse_args()
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    device_ids, primary_device = utils.parse_devices(args.device)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    config_name = os.path.splitext(os.path.basename(args.config))[0]
    args.out_dir = f'../logs/{config_name}_base_gpu{"_".join(map(str, device_ids))}'
    if args.fold is not None:
        args.out_dir = f"{args.out_dir}_fold{args.fold}"
    
    os.makedirs(args.out_dir, exist_ok=True)
    print(f"ğŸ“ Output directory: {args.out_dir}")
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    config = utils.load_json(args.config)
    utils.save_json(os.path.join(args.out_dir, 'config.json'), config)
    utils.command_log(args.out_dir)
    
    # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
    main(args.fold, device_ids, primary_device, args.out_dir, args.parallel, **config)
    
    # å®Œäº†ãƒ•ãƒ©ã‚°
    utils.save_text(os.path.join(args.out_dir, 'finish.txt'), f'Training completed at epoch')